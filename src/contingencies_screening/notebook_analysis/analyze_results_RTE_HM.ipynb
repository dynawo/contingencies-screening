{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b38e4-5d38-4d4f-9c7b-dcf76788f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_results_code\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1b9f-88ae-4078-bbcb-86ebd3be8cea",
   "metadata": {},
   "source": [
    "# GLOBAL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a060be60-c1ad-414e-b850-2a9ee624986d",
   "metadata": {},
   "source": [
    "## Load ranked contingencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da83516-dc36-47c9-8ea0-50d6ebc26e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contg = analyze_results_code.load_df(\"/home/guiu/Projects/CONT_SCR_CRV_REC/Data/Results_TAPS_Test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4560628-8a91-429f-a4eb-6e3d3416a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linear_regression_from_dict(model_data: dict):\n",
    "    if \"INTERCEPTION\" not in model_data:\n",
    "        raise ValueError(\"Model data must contain the 'INTERCEPTION' key.\")\n",
    "\n",
    "    intercept = model_data[\"INTERCEPTION\"]\n",
    "    \n",
    "    feature_names = []\n",
    "    coefficients = []\n",
    "    \n",
    "    for key, value in model_data.items():\n",
    "        if key != \"INTERCEPTION\":\n",
    "            feature_names.append(key)\n",
    "            coefficients.append(value)\n",
    "            \n",
    "    model = LinearRegression()\n",
    "    model.intercept_ = intercept\n",
    "    model.coef_ = np.array(coefficients)\n",
    "    \n",
    "    model.n_features_in_ = len(coefficients)\n",
    "    \n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        model.feature_names_in_ = np.array(feature_names, dtype=object)\n",
    "    \n",
    "    return model, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8945a70-566a-472f-977c-c1df4a1ac4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/guiu/Projects/CONT_SCR_CRV_REC/Data/FINAL_MODELS/TAPS/LR_model_Mean.json\", 'r') as f:\n",
    "    json_model_data = json.load(f)\n",
    "HM_model, feature_order = load_linear_regression_from_dict(json_model_data)\n",
    "\n",
    "df_contg[\"PREDICTED_SCORE\"] = HM_model.predict(\n",
    "    df_contg.drop(columns=[\"PREDICTED_SCORE\", \"STATUS\", \"REAL_SCORE\", \"DATE\"])[feature_order]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184f545-ec8b-40bc-a54f-d022f4a1350e",
   "metadata": {},
   "source": [
    "## MAE (Real score vs Predicted score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a42160-8eea-4391-ac3b-bc409c6bcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_contg[df_contg[\"STATUS\"] == \"BOTH\"]\n",
    "\n",
    "mae = mean_absolute_error(df_filtered[\"REAL_SCORE\"], df_filtered[\"PREDICTED_SCORE\"])\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843126f0-d95c-48a6-bb03-add2ac0e9532",
   "metadata": {},
   "source": [
    "## RMSE (Real score vs Predicted score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2409d-b8e1-49f9-ab29-f1999b61df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(df_filtered[\"REAL_SCORE\"], df_filtered[\"PREDICTED_SCORE\"])\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49338fa0-b796-4442-b238-471294804938",
   "metadata": {},
   "source": [
    "## Real score vs Predicted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab974b1-943c-4481-b2c5-22ae6162a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.real_vs_predicted_score(df_filtered, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b748258-470d-4ade-8d5e-9f16f8119c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.plot_residual_distribution(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a25011-c755-4fe8-910b-ff9667191861",
   "metadata": {},
   "source": [
    "## Hour boxplot of real scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b9771-e42a-4ae2-ba5b-dfcde01f97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.hour_boxplot(df_contg, \"REAL_SCORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dda725-6740-4812-8289-f37ec0b6efaf",
   "metadata": {},
   "source": [
    "## Hour boxplot of predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e5118-6658-4bca-969a-f8dbf2a3fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_date_1 = \"2024-12-21 00:00:00\"\n",
    "str_date_2 = \"2024-12-21 23:59:59\"\n",
    "df_contg = df_contg.sort_values(by=\"DATE\", ascending=True)\n",
    "\n",
    "mask = (df_contg[\"DATE\"] > datetime.strptime(str_date_1, \"%Y-%m-%d %H:%M:%S\")) & (\n",
    "    df_contg[\"DATE\"] <= datetime.strptime(str_date_2, \"%Y-%m-%d %H:%M:%S\")\n",
    ")\n",
    "\n",
    "df_filtered = df_contg.loc[mask]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered[\"STATUS\"] == \"BOTH\"]\n",
    "\n",
    "if not df_filtered.empty:\n",
    "    plt.figure(figsize=(12, 6))  # Set the size of the figure\n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    sns.boxplot(\n",
    "        x=df_filtered[\"DATE\"].dt.strftime(\"%Y/%m/%d, %H:%M\"),\n",
    "        y=pd.to_numeric(df_filtered[\"PREDICTED_SCORE\"]),\n",
    "    ).set(xlabel=\"DATE\", ylabel=\"PREDICTED_SCORE\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate the x-axis labels and align them to the right\n",
    "\n",
    "    # Calculate the dynamic limits for the y-axis (5th and 95th percentiles)\n",
    "    lower_limit = df_filtered[\"PREDICTED_SCORE\"].quantile(0.05)\n",
    "    upper_limit = df_filtered[\"PREDICTED_SCORE\"].quantile(0.95)\n",
    "    if not pd.isna(lower_limit) and not pd.isna(upper_limit):\n",
    "        plt.ylim(lower_limit, upper_limit)\n",
    "\n",
    "    plt.grid(color=\"grey\", linewidth=0.5)\n",
    "    plt.title(\"Boxplot of PREDICTED_SCORE\")  # Add a title to the plot\n",
    "    plt.tight_layout()  # Adjust the layout so that elements do not overlap\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The DataFrame is empty, the plot cannot be generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8418d-74c0-4779-a6c2-10dda954c287",
   "metadata": {},
   "source": [
    "## Day boxplot of real scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d0185-76b8-441b-97a5-0f97390045e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.day_boxplot(df_contg, \"REAL_SCORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7bc4e-ef40-49af-9780-80180f501a93",
   "metadata": {},
   "source": [
    "## Day boxplot of predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbb950-d238-49b9-8579-df0599f94804",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_date_1 = \"2024-12-01 00:00:00\"\n",
    "str_date_2 = \"2024-12-31 23:59:59\"\n",
    "df_contg = df_contg.sort_values(by=\"DATE\", ascending=True)\n",
    "\n",
    "mask = (df_contg[\"DATE\"] > datetime.strptime(str_date_1, \"%Y-%m-%d %H:%M:%S\")) & (\n",
    "    df_contg[\"DATE\"] <= datetime.strptime(str_date_2, \"%Y-%m-%d %H:%M:%S\")\n",
    ")\n",
    "\n",
    "df_filtered = df_contg.loc[mask]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered[\"STATUS\"] == \"BOTH\"]\n",
    "\n",
    "df_filtered[\"DATE\"] = pd.to_datetime(df_filtered[\"DATE\"], format=\"%Y-%m-%d %H:%M:%S\").dt.date\n",
    "\n",
    "if not df_filtered.empty:\n",
    "    plt.figure(figsize=(12, 6))  # Set the size of the figure\n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    sns.boxplot(x=df_filtered[\"DATE\"], y=pd.to_numeric(df_filtered[\"PREDICTED_SCORE\"])).set(\n",
    "        xlabel=\"DATE\", ylabel=\"PREDICTED_SCORE\"\n",
    "    )\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate the x-axis labels and align them to the right\n",
    "\n",
    "    # Calculate the dynamic limits for the y-axis (5th and 95th percentiles)\n",
    "    lower_limit = df_filtered[\"PREDICTED_SCORE\"].quantile(0.05)\n",
    "    upper_limit = df_filtered[\"PREDICTED_SCORE\"].quantile(0.95)\n",
    "    if not pd.isna(lower_limit) and not pd.isna(upper_limit):\n",
    "        plt.ylim(lower_limit, upper_limit)\n",
    "\n",
    "    plt.grid(color=\"grey\", linewidth=0.5)\n",
    "    plt.title(\"Boxplot of PREDICTED_SCORE\")  # Add a title to the plot\n",
    "    plt.tight_layout()  # Adjust the layout so that elements do not overlap\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The DataFrame is empty, the plot cannot be generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aacad8-5092-4fd7-bd40-2cc00227391b",
   "metadata": {},
   "source": [
    "## Real score histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c74b28-301f-465e-af54-02c95f8ffa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.score_histogram(df_contg, \"REAL_SCORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882f998-e7ed-4d1e-8783-bbddc51a0b68",
   "metadata": {},
   "source": [
    "## Predicted score histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4c3d2-fc08-4157-93db-f23eb3ea64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results_code.score_histogram(df_contg, \"PREDICTED_SCORE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cont_scr",
   "language": "python",
   "name": "cont_scr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
